const { spawn } = require('child_process');
const fs = require('fs');
const path = require('path');

// ãƒ¢ãƒ‡ãƒ«ã¨å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
const modelPath = path.join(__dirname, 'llama.cpp', 'models', 'qwen2.5-7b-instruct-q5_k_m.gguf');
const llamaPath = path.join(__dirname, 'llama.cpp', 'build', 'bin', 'llama-cli');

// ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€
const prompt = fs.readFileSync('input_prompt.txt', 'utf-8');

// llama.cppã®å®Ÿè¡Œå¼•æ•°
const args = [
  '-m', modelPath,
  '-p', prompt,
  '-n', '512',
  '--color'
];

// å®Ÿè¡Œé–‹å§‹
console.log('ðŸš€ Qwenã«ç‰©èªžç”Ÿæˆã‚’ä¾é ¼ä¸­...\n');

const llama = spawn(llamaPath, args);

llama.stdout.on('data', (data) => {
  process.stdout.write(data.toString());
});

llama.stderr.on('data', (data) => {
  console.error(`[stderr] ${data}`);
});

llama.on('close', (code) => {
  console.log(`\nðŸ§  å‡ºåŠ›å®Œäº†ï¼ˆã‚³ãƒ¼ãƒ‰: ${code}ï¼‰`);
});
